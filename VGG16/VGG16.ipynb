{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Keras in /usr/local/lib/python3.5/dist-packages (2.3.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.5/dist-packages (from Keras) (1.0.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from Keras) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from Keras) (1.14.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from Keras) (5.3)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.5/dist-packages (from Keras) (1.0.5)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from Keras) (1.3.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from Keras) (2.9.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "!pip install Keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import vgg16\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import multi_gpu_model\n",
    "# import tensorflow as tf\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "# from tensorflow.keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "import keras\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.callbacks.tensorboard_v1.TensorBoard"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorboard==1.13.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/7b/3ee06856ec30d5136cd2002408df1d111fcff269f3691147dbf3b8dc0ba2/tensorboard-1.13.0-py3-none-any.whl (3.2MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 7.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.5/dist-packages (from tensorboard==1.13.0) (1.14.5)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.5/dist-packages (from tensorboard==1.13.0) (3.8.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.5/dist-packages (from tensorboard==1.13.0) (0.33.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.5/dist-packages (from tensorboard==1.13.0) (1.12.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.5/dist-packages (from tensorboard==1.13.0) (3.1.1)\n",
      "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.5/dist-packages (from tensorboard==1.13.0) (1.26.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.5/dist-packages (from tensorboard==1.13.0) (0.15.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.5/dist-packages (from tensorboard==1.13.0) (0.7.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.5/dist-packages (from protobuf>=3.6.0->tensorboard==1.13.0) (41.0.1)\n",
      "Installing collected packages: tensorboard\n",
      "  Found existing installation: tensorboard 2.1.0\n",
      "    Uninstalling tensorboard-2.1.0:\n",
      "      Successfully uninstalled tensorboard-2.1.0\n",
      "Successfully installed tensorboard-1.13.0\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard==1.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 224, 224\n",
    "nb_train_samples = 539231\n",
    "nb_validation_samples = 240424\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "n_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 539231 images belonging to 2 classes.\n",
      "Found 240424 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = \"../../../../../raid/Data/Master_Dataset/mix/train\"\n",
    "validation_data_dir = \"../../../../../raid/Data/Master_Dataset/mix/validation\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode = 'constant',\n",
    "    cval = 1,\n",
    "    rotation_range = 5,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model = vgg16.VGG16(input_shape=(img_width, img_height, 3),\n",
    "                                     weights=\"vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n",
    "                                     include_top=False,\n",
    "                                     pooling='avg')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "x = base_model.output\n",
    "x = Dense(n_classes, activation='sigmoid', name = 'prediction')(x)\n",
    "model = Model(inputs = base_model.input, outputs = x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto',min_delta=1e-2, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=1, mode='auto',verbose=1, min_delta=1e-2, min_lr=0.00001)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "class LossHistory(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        global i\n",
    "        self.model.save(\"paper/weights_of_epoch_\" + str(i) + \".hdf5\")\n",
    "#         summarize_diagnostics(self.model_history, i)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5392/5392 [==============================] - 6689s 1s/step - loss: 0.2448 - accuracy: 0.8892 - val_loss: 0.6195 - val_accuracy: 0.8458\n",
      "Epoch 2/10\n",
      "5392/5392 [==============================] - 6379s 1s/step - loss: 0.0907 - accuracy: 0.9640 - val_loss: 0.6267 - val_accuracy: 0.8613\n",
      "Epoch 3/10\n",
      "5392/5392 [==============================] - 6289s 1s/step - loss: 0.0610 - accuracy: 0.9762 - val_loss: 0.5050 - val_accuracy: 0.8674\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 4/10\n",
      "5392/5392 [==============================] - 6117s 1s/step - loss: 0.0339 - accuracy: 0.9868 - val_loss: 1.0333 - val_accuracy: 0.8529\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 5/10\n",
      "5392/5392 [==============================] - 5949s 1s/step - loss: 0.0281 - accuracy: 0.9892 - val_loss: 0.5547 - val_accuracy: 0.8520\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 6/10\n",
      "5392/5392 [==============================] - 5971s 1s/step - loss: 0.0271 - accuracy: 0.9895 - val_loss: 0.4136 - val_accuracy: 0.8513\n",
      "Epoch 7/10\n",
      "5392/5392 [==============================] - 5958s 1s/step - loss: 0.0267 - accuracy: 0.9896 - val_loss: 0.7739 - val_accuracy: 0.8458\n",
      "Epoch 8/10\n",
      "5392/5392 [==============================] - 5956s 1s/step - loss: 0.0262 - accuracy: 0.9898 - val_loss: 0.6733 - val_accuracy: 0.8519\n",
      "Epoch 9/10\n",
      "5392/5392 [==============================] - 5946s 1s/step - loss: 0.0260 - accuracy: 0.9899 - val_loss: 1.3352 - val_accuracy: 0.8492\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "e = 10\n",
    "# model = tf.keras.models.load_model('/home/vision/mrunal/detect_deepfake/densenet121/paper/weights_of_epoch_0.hdf5')\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model = multi_gpu_model(model, gpus=2)\n",
    "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "final_location = []\n",
    "lh = LossHistory()\n",
    "\n",
    "tensorboard = TensorBoard(log_dir = \"/home/vision/mrunal/detect_deepfake/vgg_logs/{}\".format(time()))\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [tensorboard, lh, early_stop, reduce_lr]\n",
    "\n",
    "model_history = model.fit_generator(\n",
    "train_generator,\n",
    "epochs=e,\n",
    "steps_per_epoch = nb_train_samples // train_generator.batch_size,\n",
    "validation_data=validation_generator,\n",
    "verbose=1,\n",
    "validation_steps=nb_validation_samples // validation_generator.batch_size,\n",
    "callbacks=callbacks_list)\n",
    "\n",
    "#model.save(\"weights_best_\" + str(e) + \".hdf5\")\n",
    "\n",
    "# _,acc=model.evaluate_generator(validation_generator, steps=nb_validation_samples, max_queue_size=10,verbose=1, workers=1, use_multiprocessing=False)\n",
    "# print('> %.3f' % (acc * 100.0))\n",
    "\n",
    "loss=model_history.history['loss']\n",
    "acc=model_history.history['accuracy']\n",
    "valacc=model_history.history['val_accuracy']\n",
    "valloss=model_history.history['val_loss']\n",
    "location = [e,loss,acc,valacc, valloss]\n",
    "final_location.append(location)\n",
    "save = pd.DataFrame(final_location,columns=['epochs','loss','acc','valacc','valloss'])\n",
    "save.to_csv('/home/vision/mrunal/detect_deepfake/VGG/paper/VGG16_log_'+str(e)+'.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
